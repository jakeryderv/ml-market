{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Simple RandomForestRegressor - Stock Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from ml_market.data import fetch_ohlcv, load_sector_data, load_macro_data\n",
    "from ml_market.features import compute_all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (23140, 112)\n",
      "Ticker mapping: {'AAPL': 0, 'AMZN': 1, 'AVGO': 2, 'GOOG': 3, 'GOOGL': 4, 'META': 5, 'MSFT': 6, 'NFLX': 7, 'NVDA': 8, 'TSLA': 9}\n",
      "Final shape with ticker_code: (23140, 112)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker_code</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>lag0_return_1d</th>\n",
       "      <th>lag1_return_1d</th>\n",
       "      <th>lag5_return_1d</th>\n",
       "      <th>...</th>\n",
       "      <th>dxy_ret_1d</th>\n",
       "      <th>dxy_vol_20</th>\n",
       "      <th>dxy_mom_10</th>\n",
       "      <th>vix_close</th>\n",
       "      <th>vix_ret_1d</th>\n",
       "      <th>vix_vol_20</th>\n",
       "      <th>vix_mom_10</th>\n",
       "      <th>spread_stock_vs_sector</th>\n",
       "      <th>spread_stock_vs_spy</th>\n",
       "      <th>spread_qqq_vs_spy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-10-16</td>\n",
       "      <td>25.095493</td>\n",
       "      <td>25.144885</td>\n",
       "      <td>24.814858</td>\n",
       "      <td>24.929358</td>\n",
       "      <td>156930400</td>\n",
       "      <td>-0.007331</td>\n",
       "      <td>0.014971</td>\n",
       "      <td>0.023927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.004504</td>\n",
       "      <td>-0.013461</td>\n",
       "      <td>15.05</td>\n",
       "      <td>-0.062305</td>\n",
       "      <td>0.075163</td>\n",
       "      <td>-0.28128</td>\n",
       "      <td>-0.009241</td>\n",
       "      <td>-0.011877</td>\n",
       "      <td>-0.000367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-10-16</td>\n",
       "      <td>28.263500</td>\n",
       "      <td>28.547001</td>\n",
       "      <td>28.015499</td>\n",
       "      <td>28.538000</td>\n",
       "      <td>86316000</td>\n",
       "      <td>0.014793</td>\n",
       "      <td>0.032322</td>\n",
       "      <td>0.012454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.004504</td>\n",
       "      <td>-0.013461</td>\n",
       "      <td>15.05</td>\n",
       "      <td>-0.062305</td>\n",
       "      <td>0.075163</td>\n",
       "      <td>-0.28128</td>\n",
       "      <td>0.012883</td>\n",
       "      <td>0.010246</td>\n",
       "      <td>-0.000367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-10-16</td>\n",
       "      <td>9.307852</td>\n",
       "      <td>9.313960</td>\n",
       "      <td>9.155139</td>\n",
       "      <td>9.244476</td>\n",
       "      <td>19866000</td>\n",
       "      <td>-0.006564</td>\n",
       "      <td>0.037545</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.004504</td>\n",
       "      <td>-0.013461</td>\n",
       "      <td>15.05</td>\n",
       "      <td>-0.062305</td>\n",
       "      <td>0.075163</td>\n",
       "      <td>-0.28128</td>\n",
       "      <td>-0.008474</td>\n",
       "      <td>-0.011110</td>\n",
       "      <td>-0.000367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-10-16</td>\n",
       "      <td>32.979812</td>\n",
       "      <td>33.022519</td>\n",
       "      <td>32.636659</td>\n",
       "      <td>32.884960</td>\n",
       "      <td>32222000</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.016248</td>\n",
       "      <td>0.006962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.004504</td>\n",
       "      <td>-0.013461</td>\n",
       "      <td>15.05</td>\n",
       "      <td>-0.062305</td>\n",
       "      <td>0.075163</td>\n",
       "      <td>-0.28128</td>\n",
       "      <td>-0.001215</td>\n",
       "      <td>-0.003851</td>\n",
       "      <td>-0.000367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-10-16</td>\n",
       "      <td>34.531829</td>\n",
       "      <td>34.572549</td>\n",
       "      <td>34.218988</td>\n",
       "      <td>34.527855</td>\n",
       "      <td>36316000</td>\n",
       "      <td>0.003319</td>\n",
       "      <td>0.018533</td>\n",
       "      <td>0.006357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.004504</td>\n",
       "      <td>-0.013461</td>\n",
       "      <td>15.05</td>\n",
       "      <td>-0.062305</td>\n",
       "      <td>0.075163</td>\n",
       "      <td>-0.28128</td>\n",
       "      <td>0.001409</td>\n",
       "      <td>-0.001228</td>\n",
       "      <td>-0.000367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2015-10-16</td>\n",
       "      <td>95.590715</td>\n",
       "      <td>96.992072</td>\n",
       "      <td>94.765798</td>\n",
       "      <td>96.942383</td>\n",
       "      <td>25412900</td>\n",
       "      <td>0.016465</td>\n",
       "      <td>0.020091</td>\n",
       "      <td>0.008327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.004504</td>\n",
       "      <td>-0.013461</td>\n",
       "      <td>15.05</td>\n",
       "      <td>-0.062305</td>\n",
       "      <td>0.075163</td>\n",
       "      <td>-0.28128</td>\n",
       "      <td>0.014555</td>\n",
       "      <td>0.011919</td>\n",
       "      <td>-0.000367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2015-10-16</td>\n",
       "      <td>40.895576</td>\n",
       "      <td>41.347845</td>\n",
       "      <td>40.791207</td>\n",
       "      <td>41.321751</td>\n",
       "      <td>26450300</td>\n",
       "      <td>0.010636</td>\n",
       "      <td>0.007070</td>\n",
       "      <td>-0.007165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.004504</td>\n",
       "      <td>-0.013461</td>\n",
       "      <td>15.05</td>\n",
       "      <td>-0.062305</td>\n",
       "      <td>0.075163</td>\n",
       "      <td>-0.28128</td>\n",
       "      <td>0.008726</td>\n",
       "      <td>0.006090</td>\n",
       "      <td>-0.000367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2015-10-16</td>\n",
       "      <td>10.021000</td>\n",
       "      <td>10.165000</td>\n",
       "      <td>9.841000</td>\n",
       "      <td>9.899000</td>\n",
       "      <td>213405000</td>\n",
       "      <td>-0.020774</td>\n",
       "      <td>-0.082917</td>\n",
       "      <td>-0.013922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.004504</td>\n",
       "      <td>-0.013461</td>\n",
       "      <td>15.05</td>\n",
       "      <td>-0.062305</td>\n",
       "      <td>0.075163</td>\n",
       "      <td>-0.28128</td>\n",
       "      <td>-0.022684</td>\n",
       "      <td>-0.025320</td>\n",
       "      <td>-0.000367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2015-10-16</td>\n",
       "      <td>0.668782</td>\n",
       "      <td>0.683363</td>\n",
       "      <td>0.667081</td>\n",
       "      <td>0.677044</td>\n",
       "      <td>448396000</td>\n",
       "      <td>0.015677</td>\n",
       "      <td>0.002558</td>\n",
       "      <td>-0.003821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.004504</td>\n",
       "      <td>-0.013461</td>\n",
       "      <td>15.05</td>\n",
       "      <td>-0.062305</td>\n",
       "      <td>0.075163</td>\n",
       "      <td>-0.28128</td>\n",
       "      <td>0.013767</td>\n",
       "      <td>0.011130</td>\n",
       "      <td>-0.000367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2015-10-16</td>\n",
       "      <td>14.869333</td>\n",
       "      <td>15.365333</td>\n",
       "      <td>14.858000</td>\n",
       "      <td>15.134000</td>\n",
       "      <td>65017500</td>\n",
       "      <td>0.025756</td>\n",
       "      <td>0.020426</td>\n",
       "      <td>-0.026597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.004504</td>\n",
       "      <td>-0.013461</td>\n",
       "      <td>15.05</td>\n",
       "      <td>-0.062305</td>\n",
       "      <td>0.075163</td>\n",
       "      <td>-0.28128</td>\n",
       "      <td>0.023846</td>\n",
       "      <td>0.021209</td>\n",
       "      <td>-0.000367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ticker_code       date       open       high        low      close  \\\n",
       "0            0 2015-10-16  25.095493  25.144885  24.814858  24.929358   \n",
       "1            1 2015-10-16  28.263500  28.547001  28.015499  28.538000   \n",
       "2            2 2015-10-16   9.307852   9.313960   9.155139   9.244476   \n",
       "3            3 2015-10-16  32.979812  33.022519  32.636659  32.884960   \n",
       "4            4 2015-10-16  34.531829  34.572549  34.218988  34.527855   \n",
       "5            5 2015-10-16  95.590715  96.992072  94.765798  96.942383   \n",
       "6            6 2015-10-16  40.895576  41.347845  40.791207  41.321751   \n",
       "7            7 2015-10-16  10.021000  10.165000   9.841000   9.899000   \n",
       "8            8 2015-10-16   0.668782   0.683363   0.667081   0.677044   \n",
       "9            9 2015-10-16  14.869333  15.365333  14.858000  15.134000   \n",
       "\n",
       "      volume  lag0_return_1d  lag1_return_1d  lag5_return_1d  ...  dxy_ret_1d  \\\n",
       "0  156930400       -0.007331        0.014971        0.023927  ...    0.001801   \n",
       "1   86316000        0.014793        0.032322        0.012454  ...    0.001801   \n",
       "2   19866000       -0.006564        0.037545        0.001886  ...    0.001801   \n",
       "3   32222000        0.000695        0.016248        0.006962  ...    0.001801   \n",
       "4   36316000        0.003319        0.018533        0.006357  ...    0.001801   \n",
       "5   25412900        0.016465        0.020091        0.008327  ...    0.001801   \n",
       "6   26450300        0.010636        0.007070       -0.007165  ...    0.001801   \n",
       "7  213405000       -0.020774       -0.082917       -0.013922  ...    0.001801   \n",
       "8  448396000        0.015677        0.002558       -0.003821  ...    0.001801   \n",
       "9   65017500        0.025756        0.020426       -0.026597  ...    0.001801   \n",
       "\n",
       "   dxy_vol_20  dxy_mom_10  vix_close  vix_ret_1d  vix_vol_20  vix_mom_10  \\\n",
       "0    0.004504   -0.013461      15.05   -0.062305    0.075163    -0.28128   \n",
       "1    0.004504   -0.013461      15.05   -0.062305    0.075163    -0.28128   \n",
       "2    0.004504   -0.013461      15.05   -0.062305    0.075163    -0.28128   \n",
       "3    0.004504   -0.013461      15.05   -0.062305    0.075163    -0.28128   \n",
       "4    0.004504   -0.013461      15.05   -0.062305    0.075163    -0.28128   \n",
       "5    0.004504   -0.013461      15.05   -0.062305    0.075163    -0.28128   \n",
       "6    0.004504   -0.013461      15.05   -0.062305    0.075163    -0.28128   \n",
       "7    0.004504   -0.013461      15.05   -0.062305    0.075163    -0.28128   \n",
       "8    0.004504   -0.013461      15.05   -0.062305    0.075163    -0.28128   \n",
       "9    0.004504   -0.013461      15.05   -0.062305    0.075163    -0.28128   \n",
       "\n",
       "   spread_stock_vs_sector  spread_stock_vs_spy  spread_qqq_vs_spy  \n",
       "0               -0.009241            -0.011877          -0.000367  \n",
       "1                0.012883             0.010246          -0.000367  \n",
       "2               -0.008474            -0.011110          -0.000367  \n",
       "3               -0.001215            -0.003851          -0.000367  \n",
       "4                0.001409            -0.001228          -0.000367  \n",
       "5                0.014555             0.011919          -0.000367  \n",
       "6                0.008726             0.006090          -0.000367  \n",
       "7               -0.022684            -0.025320          -0.000367  \n",
       "8                0.013767             0.011130          -0.000367  \n",
       "9                0.023846             0.021209          -0.000367  \n",
       "\n",
       "[10 rows x 112 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TICKERS = [\n",
    "    'NVDA',\n",
    "    'MSFT',\n",
    "    'AAPL',\n",
    "    'AVGO',\n",
    "    'AMZN',\n",
    "    'TSLA',\n",
    "    'META',\n",
    "    'GOOGL',\n",
    "    'GOOG',\n",
    "    'NFLX',\n",
    "]\n",
    "START = \"2015-01-01\"\n",
    "END = \"2025-01-01\"\n",
    "\n",
    "# Load data\n",
    "stocks_df = fetch_ohlcv(TICKERS, START, END)\n",
    "sector_df = load_sector_data(start=START, end=END)\n",
    "macro_df = load_macro_data(start=START, end=END)\n",
    "\n",
    "df = compute_all_features(stocks_df, sector_df, macro_df)\n",
    "print(f\"Shape: {df.shape}\")\n",
    "\n",
    "# map tickers -> integer codes\n",
    "unique_tickers = sorted(df['ticker'].unique())\n",
    "ticker_to_code = {t: i for i, t in enumerate(unique_tickers)}\n",
    "df['ticker_code'] = df['ticker'].map(ticker_to_code)\n",
    "# drop ticker string\n",
    "df = df.drop(columns=['ticker'])\n",
    "# move ticker_code to first col\n",
    "cols = [\"ticker_code\"] + [c for c in df.columns if c != \"ticker_code\"]\n",
    "df = df[cols]\n",
    "\n",
    "print(\"Ticker mapping:\", ticker_to_code)\n",
    "print(f\"Final shape with ticker_code: {df.shape}\")\n",
    "\n",
    "df = df.sort_values(['date', 'ticker_code'])\n",
    "df.head(len(ticker_to_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94e33d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ticker_code',\n",
       " 'date',\n",
       " 'open',\n",
       " 'high',\n",
       " 'low',\n",
       " 'close',\n",
       " 'volume',\n",
       " 'lag0_return_1d',\n",
       " 'lag1_return_1d',\n",
       " 'lag5_return_1d',\n",
       " 'lag10_return_1d',\n",
       " 'lag20_return_1d',\n",
       " 'lag0_return_5d',\n",
       " 'lag1_return_5d',\n",
       " 'lag5_return_5d',\n",
       " 'lag10_return_5d',\n",
       " 'lag20_return_5d',\n",
       " 'lag0_return_10d',\n",
       " 'lag1_return_10d',\n",
       " 'lag5_return_10d',\n",
       " 'lag10_return_10d',\n",
       " 'lag20_return_10d',\n",
       " 'lag0_return_20d',\n",
       " 'lag1_return_20d',\n",
       " 'lag5_return_20d',\n",
       " 'lag10_return_20d',\n",
       " 'lag20_return_20d',\n",
       " 'return_rolling_mean_5d',\n",
       " 'return_rolling_std_5d',\n",
       " 'return_rolling_std_20d',\n",
       " 'return_volatility_ratio_5d_20d',\n",
       " 'return_autocorr_5d',\n",
       " 'trend_sma_5d',\n",
       " 'trend_sma_10d',\n",
       " 'trend_sma_20d',\n",
       " 'trend_sma_50d',\n",
       " 'trend_sma_200d',\n",
       " 'trend_ema_10d',\n",
       " 'trend_ema_20d',\n",
       " 'trend_ema_50d',\n",
       " 'trend_sma_diff_5d_20d',\n",
       " 'trend_sma_diff_10d_50d',\n",
       " 'trend_macd',\n",
       " 'trend_macd_signal',\n",
       " 'trend_macd_histogram',\n",
       " 'trend_price_to_sma_20d',\n",
       " 'trend_price_to_sma_50d',\n",
       " 'trend_roc_10d',\n",
       " 'trend_roc_20d',\n",
       " 'trend_adx_14d',\n",
       " 'momentum_rsi_14d',\n",
       " 'momentum_stochastic_k',\n",
       " 'momentum_stochastic_d',\n",
       " 'momentum_williams_r',\n",
       " 'volatility_true_range',\n",
       " 'volatility_atr_14d',\n",
       " 'volatility_atr_percent',\n",
       " 'volatility_bb_middle',\n",
       " 'volatility_bb_upper',\n",
       " 'volatility_bb_lower',\n",
       " 'volatility_bb_width',\n",
       " 'volatility_bb_position',\n",
       " 'volatility_rolling_20d',\n",
       " 'volume_change_1d',\n",
       " 'volume_sma_20d',\n",
       " 'volume_ratio_to_sma',\n",
       " 'volume_trend_slope_5d',\n",
       " 'volume_vwap_20d',\n",
       " 'volume_vwap_deviation',\n",
       " 'volume_obv',\n",
       " 'volume_obv_sma_20d',\n",
       " 'volume_obv_ratio',\n",
       " 'stat_return_zscore_20d',\n",
       " 'stat_volume_zscore_20d',\n",
       " 'stat_close_zscore_20d',\n",
       " 'stat_return_percentile_20d',\n",
       " 'stat_volume_percentile_20d',\n",
       " 'stat_return_skew_20d',\n",
       " 'stat_return_kurtosis_20d',\n",
       " 'stat_close_minmax_20d',\n",
       " 'target_return_1d',\n",
       " 'target_return_5d',\n",
       " 'target_return_10d',\n",
       " 'target_direction_up_1d',\n",
       " 'target_direction_3class_1d',\n",
       " 'xlk_close',\n",
       " 'xlk_ret_1d',\n",
       " 'xlk_vol_20',\n",
       " 'xlk_mom_10',\n",
       " 'spy_close',\n",
       " 'spy_ret_1d',\n",
       " 'spy_vol_20',\n",
       " 'spy_mom_10',\n",
       " 'qqq_close',\n",
       " 'qqq_ret_1d',\n",
       " 'qqq_vol_20',\n",
       " 'qqq_mom_10',\n",
       " 'tlt_close',\n",
       " 'tlt_ret_1d',\n",
       " 'tlt_vol_20',\n",
       " 'tlt_mom_10',\n",
       " 'dxy_close',\n",
       " 'dxy_ret_1d',\n",
       " 'dxy_vol_20',\n",
       " 'dxy_mom_10',\n",
       " 'vix_close',\n",
       " 'vix_ret_1d',\n",
       " 'vix_vol_20',\n",
       " 'vix_mom_10',\n",
       " 'spread_stock_vs_sector',\n",
       " 'spread_stock_vs_spy',\n",
       " 'spread_qqq_vs_spy']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c9bcf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\n",
    "    \"date\",\n",
    "    \"target_return_1d\",\n",
    "    \"target_return_5d\",\n",
    "    \"target_return_10d\",\n",
    "    \"target_direction_up_1d\",\n",
    "    \"target_direction_3class_1d\",\n",
    "]\n",
    "suspect_cols = [\n",
    "'xlk_close',\n",
    "'xlk_ret_1d',\n",
    "'xlk_vol_20',\n",
    "'xlk_mom_10',\n",
    "'spy_close',\n",
    "'spy_ret_1d',\n",
    "'spy_vol_20',\n",
    "'spy_mom_10',\n",
    "'qqq_close',\n",
    "'qqq_ret_1d',\n",
    "'qqq_vol_20',\n",
    "'qqq_mom_10',\n",
    "'tlt_close',\n",
    "'tlt_ret_1d',\n",
    "'tlt_vol_20',\n",
    "'tlt_mom_10',\n",
    "'dxy_close',\n",
    "'dxy_ret_1d',\n",
    "'dxy_vol_20',\n",
    "'dxy_mom_10',\n",
    "'vix_close',\n",
    "'vix_ret_1d',\n",
    "'vix_vol_20',\n",
    "'vix_mom_10',\n",
    "'spread_stock_vs_sector',\n",
    "'spread_stock_vs_spy',\n",
    "'spread_qqq_vs_spy'\n",
    "]\n",
    "drop_cols_complete = drop_cols + suspect_cols\n",
    "\n",
    "feature_cols = [c for c in df.columns if c not in drop_cols_complete]\n",
    "target = \"target_return_1d\"\n",
    "dates = df['date']\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cea85a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ---- Walk-forward settings ----\n",
    "TRAIN_FRAC = 0.70\n",
    "TEST_FRAC  = 0.05\n",
    "EMBARGO    = 10     # because your max lookahead = 10d\n",
    "\n",
    "# ---- Prepare date universe ----\n",
    "unique_dates = np.array(sorted(dates.unique()))\n",
    "N = len(unique_dates)\n",
    "\n",
    "train_size = int(N * TRAIN_FRAC)\n",
    "test_size  = int(N * TEST_FRAC)\n",
    "\n",
    "splits = []\n",
    "i = 0\n",
    "\n",
    "# ---- Build walk-forward splits ----\n",
    "while i + train_size + EMBARGO + test_size <= N:\n",
    "    train_dates = unique_dates[i : i + train_size]\n",
    "    test_dates  = unique_dates[i + train_size + EMBARGO :\n",
    "                               i + train_size + EMBARGO + test_size]\n",
    "    \n",
    "    train_mask = dates.isin(train_dates)\n",
    "    test_mask  = dates.isin(test_dates)\n",
    "\n",
    "    X_train, y_train = X[train_mask], y[train_mask]\n",
    "    X_test,  y_test  = X[test_mask],  y[test_mask]\n",
    "\n",
    "    splits.append((X_train, y_train, X_test, y_test))\n",
    "    \n",
    "    i += test_size   # slide window by size of test period\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a325dc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Metrics:\n",
      "rmse: 0.022843\n",
      "mae: 0.015209\n",
      "corr: 0.474568\n",
      "dir_acc: 0.687826\n",
      "signed_error: 0.000315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "rf_metrics = {\n",
    "    \"rmse\": [],\n",
    "    \"mae\": [],\n",
    "    \"corr\": [],\n",
    "    \"dir_acc\": [],\n",
    "    \"signed_error\": []\n",
    "}\n",
    "\n",
    "for X_train, y_train, X_test, y_test in splits:\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=400,\n",
    "        min_samples_leaf=2,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    # core metrics\n",
    "    mse = mean_squared_error(y_test, preds)\n",
    "    rmse = mse ** 0.5\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "\n",
    "    # correlation (nan-safe)\n",
    "    corr = np.corrcoef(y_test, preds)[0, 1] if len(y_test) > 2 else np.nan\n",
    "\n",
    "    # directional accuracy\n",
    "    dir_acc = np.mean(np.sign(preds) == np.sign(y_test))\n",
    "\n",
    "    # signed error (bias detection)\n",
    "    signed_err = np.mean(preds - y_test)\n",
    "\n",
    "    rf_metrics[\"rmse\"].append(rmse)\n",
    "    rf_metrics[\"mae\"].append(mae)\n",
    "    rf_metrics[\"corr\"].append(corr)\n",
    "    rf_metrics[\"dir_acc\"].append(dir_acc)\n",
    "    rf_metrics[\"signed_error\"].append(signed_err)\n",
    "\n",
    "print(\"RandomForest Metrics:\")\n",
    "for k, v in rf_metrics.items():\n",
    "    print(f\"{k}: {np.nanmean(v):.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e4c5820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Metrics:\n",
      "rmse: 0.022706\n",
      "mae: 0.015093\n",
      "corr: 0.476626\n",
      "dir_acc: 0.684000\n",
      "signed_error: 0.000107\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "xgb_metrics = {\n",
    "    \"rmse\": [],\n",
    "    \"mae\": [],\n",
    "    \"corr\": [],\n",
    "    \"dir_acc\": [],\n",
    "    \"signed_error\": []\n",
    "}\n",
    "\n",
    "for X_train, y_train, X_test, y_test in splits:\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=700,\n",
    "        learning_rate=0.03,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective=\"reg:squarederror\",\n",
    "        tree_method=\"hist\"\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, preds)\n",
    "    rmse = mse ** 0.5\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "\n",
    "    corr = np.corrcoef(y_test, preds)[0, 1] if len(y_test) > 2 else np.nan\n",
    "\n",
    "    dir_acc = np.mean(np.sign(preds) == np.sign(y_test))\n",
    "    signed_err = np.mean(preds - y_test)\n",
    "\n",
    "    xgb_metrics[\"rmse\"].append(rmse)\n",
    "    xgb_metrics[\"mae\"].append(mae)\n",
    "    xgb_metrics[\"corr\"].append(corr)\n",
    "    xgb_metrics[\"dir_acc\"].append(dir_acc)\n",
    "    xgb_metrics[\"signed_error\"].append(signed_err)\n",
    "\n",
    "print(\"XGBoost Metrics:\")\n",
    "for k, v in xgb_metrics.items():\n",
    "    print(f\"{k}: {np.nanmean(v):.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6352046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001000 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19432\n",
      "[LightGBM] [Info] Number of data points in the train set: 16190, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 0.001447\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19432\n",
      "[LightGBM] [Info] Number of data points in the train set: 16190, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 0.001208\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19432\n",
      "[LightGBM] [Info] Number of data points in the train set: 16190, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 0.001186\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000890 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19432\n",
      "[LightGBM] [Info] Number of data points in the train set: 16190, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 0.001303\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000915 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19432\n",
      "[LightGBM] [Info] Number of data points in the train set: 16190, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 0.001290\n",
      "LightGBM Metrics:\n",
      "rmse: 0.022449\n",
      "mae: 0.014875\n",
      "corr: 0.491498\n",
      "dir_acc: 0.691826\n",
      "signed_error: -0.000067\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "lgb_metrics = {\n",
    "    \"rmse\": [],\n",
    "    \"mae\": [],\n",
    "    \"corr\": [],\n",
    "    \"dir_acc\": [],\n",
    "    \"signed_error\": []\n",
    "}\n",
    "\n",
    "for X_train, y_train, X_test, y_test in splits:\n",
    "    model = lgb.LGBMRegressor(\n",
    "        n_estimators=700,\n",
    "        learning_rate=0.02,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, preds)\n",
    "    rmse = mse ** 0.5\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "\n",
    "    corr = np.corrcoef(y_test, preds)[0, 1] if len(y_test) > 2 else np.nan\n",
    "\n",
    "    dir_acc = np.mean(np.sign(preds) == np.sign(y_test))\n",
    "    signed_err = np.mean(preds - y_test)\n",
    "\n",
    "    lgb_metrics[\"rmse\"].append(rmse)\n",
    "    lgb_metrics[\"mae\"].append(mae)\n",
    "    lgb_metrics[\"corr\"].append(corr)\n",
    "    lgb_metrics[\"dir_acc\"].append(dir_acc)\n",
    "    lgb_metrics[\"signed_error\"].append(signed_err)\n",
    "\n",
    "print(\"LightGBM Metrics:\")\n",
    "for k, v in lgb_metrics.items():\n",
    "    print(f\"{k}: {np.nanmean(v):.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e00be857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>Directional_Acc</th>\n",
       "      <th>Signed_Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.022843</td>\n",
       "      <td>0.015209</td>\n",
       "      <td>0.474568</td>\n",
       "      <td>0.687826</td>\n",
       "      <td>0.000315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.022706</td>\n",
       "      <td>0.015093</td>\n",
       "      <td>0.476626</td>\n",
       "      <td>0.684000</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.022449</td>\n",
       "      <td>0.014875</td>\n",
       "      <td>0.491498</td>\n",
       "      <td>0.691826</td>\n",
       "      <td>-0.000067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model      RMSE       MAE  Correlation  Directional_Acc  \\\n",
       "0  RandomForest  0.022843  0.015209     0.474568         0.687826   \n",
       "1       XGBoost  0.022706  0.015093     0.476626         0.684000   \n",
       "2      LightGBM  0.022449  0.014875     0.491498         0.691826   \n",
       "\n",
       "   Signed_Error  \n",
       "0      0.000315  \n",
       "1      0.000107  \n",
       "2     -0.000067  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "summary_df = pd.DataFrame({\n",
    "    \"Model\": [\"RandomForest\", \"XGBoost\", \"LightGBM\"],\n",
    "    \"RMSE\": [\n",
    "        np.nanmean(rf_metrics[\"rmse\"]),\n",
    "        np.nanmean(xgb_metrics[\"rmse\"]),\n",
    "        np.nanmean(lgb_metrics[\"rmse\"])\n",
    "    ],\n",
    "    \"MAE\": [\n",
    "        np.nanmean(rf_metrics[\"mae\"]),\n",
    "        np.nanmean(xgb_metrics[\"mae\"]),\n",
    "        np.nanmean(lgb_metrics[\"mae\"])\n",
    "    ],\n",
    "    \"Correlation\": [\n",
    "        np.nanmean(rf_metrics[\"corr\"]),\n",
    "        np.nanmean(xgb_metrics[\"corr\"]),\n",
    "        np.nanmean(lgb_metrics[\"corr\"])\n",
    "    ],\n",
    "    \"Directional_Acc\": [\n",
    "        np.nanmean(rf_metrics[\"dir_acc\"]),\n",
    "        np.nanmean(xgb_metrics[\"dir_acc\"]),\n",
    "        np.nanmean(lgb_metrics[\"dir_acc\"])\n",
    "    ],\n",
    "    \"Signed_Error\": [\n",
    "        np.nanmean(rf_metrics[\"signed_error\"]),\n",
    "        np.nanmean(xgb_metrics[\"signed_error\"]),\n",
    "        np.nanmean(lgb_metrics[\"signed_error\"])\n",
    "    ]\n",
    "})\n",
    "\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2aa2edd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19432\n",
      "[LightGBM] [Info] Number of data points in the train set: 23140, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 0.001408\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>gain</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lag0_return_1d</td>\n",
       "      <td>67.195173</td>\n",
       "      <td>906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ticker_code</td>\n",
       "      <td>12.345509</td>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>stat_return_zscore_20d</td>\n",
       "      <td>8.308432</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>stat_return_percentile_20d</td>\n",
       "      <td>5.623520</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lag5_return_1d</td>\n",
       "      <td>3.229267</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>volume_ratio_to_sma</td>\n",
       "      <td>2.906633</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lag1_return_1d</td>\n",
       "      <td>2.881649</td>\n",
       "      <td>601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>volume_obv</td>\n",
       "      <td>2.825030</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>volume_obv_sma_20d</td>\n",
       "      <td>2.650381</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>volume</td>\n",
       "      <td>2.600474</td>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>volume_trend_slope_5d</td>\n",
       "      <td>2.507593</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>volume_change_1d</td>\n",
       "      <td>2.392327</td>\n",
       "      <td>545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>stat_return_kurtosis_20d</td>\n",
       "      <td>2.385789</td>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>return_rolling_std_20d</td>\n",
       "      <td>2.247663</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>trend_macd</td>\n",
       "      <td>2.140194</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>lag20_return_5d</td>\n",
       "      <td>2.058594</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>return_rolling_std_5d</td>\n",
       "      <td>1.852600</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>volatility_true_range</td>\n",
       "      <td>1.807830</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lag20_return_10d</td>\n",
       "      <td>1.773814</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>stat_volume_zscore_20d</td>\n",
       "      <td>1.772801</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feature       gain  split\n",
       "6               lag0_return_1d  67.195173    906\n",
       "0                  ticker_code  12.345509    589\n",
       "71      stat_return_zscore_20d   8.308432    538\n",
       "74  stat_return_percentile_20d   5.623520    174\n",
       "8               lag5_return_1d   3.229267    565\n",
       "64         volume_ratio_to_sma   2.906633    475\n",
       "7               lag1_return_1d   2.881649    601\n",
       "68                  volume_obv   2.825030    513\n",
       "69          volume_obv_sma_20d   2.650381    470\n",
       "5                       volume   2.600474    448\n",
       "65       volume_trend_slope_5d   2.507593    495\n",
       "62            volume_change_1d   2.392327    545\n",
       "77    stat_return_kurtosis_20d   2.385789    469\n",
       "28      return_rolling_std_20d   2.247663    313\n",
       "41                  trend_macd   2.140194    210\n",
       "15             lag20_return_5d   2.058594    465\n",
       "27       return_rolling_std_5d   1.852600    342\n",
       "53       volatility_true_range   1.807830    367\n",
       "20            lag20_return_10d   1.773814    386\n",
       "72      stat_volume_zscore_20d   1.772801    386"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Train one LightGBM model on the full training window (not walk-forward)\n",
    "# This is okay for feature-importance only\n",
    "model_full = lgb.LGBMRegressor(\n",
    "    n_estimators=700,\n",
    "    learning_rate=0.02,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8\n",
    ")\n",
    "\n",
    "model_full.fit(X, y)\n",
    "\n",
    "# Extract importances\n",
    "gain_importance = model_full.booster_.feature_importance(importance_type='gain')\n",
    "split_importance = model_full.booster_.feature_importance(importance_type='split')\n",
    "\n",
    "feature_names = model_full.booster_.feature_name()\n",
    "\n",
    "fi_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"gain\": gain_importance,\n",
    "    \"split\": split_importance\n",
    "}).sort_values(\"gain\", ascending=False)\n",
    "\n",
    "fi_df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f98ce8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
